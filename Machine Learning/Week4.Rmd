---
title: "Week4"
author: "Matteo Gambera"
date: "5 aprile 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Regularide regression
l'idea è fittare una regresione lineare e penalizzare i alcuni predittori.
perchè alcune variabili sono correlate tra di loro.
per esempio

* y = b0 + b1x1 + b2x2

se x1 e x2 sono molto correlate

* y = b0 + (b1 + b2)x1

il risultato è :

* una buona stima di y
* una stima con dei bias
* riduciamo molto la varianza

facciamo un esempio 
```{r}
data(Prostate); 
str(Prostate)
```
Vogliamo fare una predizion e sul prostate cancer PSA basato su un numero grosso di predittoroi.
Più aumento il numero di predittori nel train più l'errore diminuisce però non è detto che succeda lo stesso con il test

# Combining predictors
```{r}
library(ISLR);library(ggplot2); library(caret)
data(Wage);
Wage <- subset(Wage, select = -c(logwage))
## Create a building data set and a validation set
inBuild <- createDataPartition(y = Wage$wage, p = 0.7,
                               list = FALSE)
buildData <- Wage[inBuild,]
validation <- Wage[-inBuild,]

inTrain <- createDataPartition(y = Wage$wage , p = 0.7,
                               list = FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain,]

dim(validation); dim(training); dim(testing)
```

costruisco due modelli diversi
```{r}

mod1 <- train(wage ~ ., method="glm", data = training, na.action = na.omit)
mod2 <- train(wage ~. , method = "rf", data = training,
              trControl=trainControl(method = "cv"),number =3,
              na.action = na.omit)

```
### Predict on testing set
```{r}
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
qplot(pred1,pred2, colour = wage, data = testing)
```
Confronto tra le due strategie, abbastanza correlate tranne quando ci sono Wage grossi (colore azzurino)

### fit a model that combines predictors

```{r}
predDF <- data.frame(pred1,pred2, wage = testing$wage)
## creo un nuovo modello che predice wage basandosi sulle due pred
## per questo motivo ho creato il dataframe predDF
combModfit <- train(wage ~., method = "gam", data = predDF)
combPred <- predict(combModfit, predDF)
```
se calcolo gli SMRE vedo che quello del modello combinato è inferiore
```{r}
sqrt(sum((pred1 - testing$wage)^2))
sqrt(sum((pred2 - testing$wage)^2))
sqrt(sum((combPred - testing$wage)^2))
```

### predict on validation set
```{r}
pred1V <- predict(mod1, validation)
pred2V <- predict(mod2, validation)
predVDF <- data.frame(pred1=pred1V, pred2 = pred2V)
combPredV <- predict(combModfit,predVDF)
```
```{r}
sqrt(sum((pred1V - validation$wage)^2))
sqrt(sum((pred2V - validation$wage)^2))
sqrt(sum((combPredV - validation$wage)^2))
```
In questo caso non migliora l'accuratezza

# Forecasting
è un tipo di problema di predizione
è utilizzato molto con time series

```{r}
library(quantmod)
from.dat <- as.Date("01/01/08", format = "%m/%d/%y")
to.dat <- as.Date("06/04/20", format = "%m/%d/%y")
getSymbols("GOOG", src="yahoo", from = from.dat, to = to.dat)
head(GOOG)
```
### summarize monthly and store as time serie
```{r}
mGoog <- to.monthly(GOOG)
## prendo i valori di apertura
googOpen <- Op(mGoog)
## creo un time series object
ts1 <- ts(googOpen, frequency = 12)
## plotto i 7 anni
plot(ts1)

```
Esempi di decomposizione di time serie
[esempio](https://www.otexts.org/fpp/6/1)

### decompose time series in part
```{r fig.height=10}
plot(decompose(ts1))
```
### training and test sets
```{r}
ts1Train <- window(ts1, start =1, end = 11)
ts1Test <- window(ts1, start = 11, end = (14-0.01))
```

### Simple moving average
```{r}
library(smooth)
library(Mcomp)
plot(ts1Train)
lines(ma(ts1Train, order = 3), col ="red")
```

### Exponential smoothing
```{r}
ets1 <- ets(ts1Train, model ="MMM")
fcast <- forecast(ets1)
plot(fcast)
lines(ts1Test, col = "red")
```
### get the accuracy 
```{r}
accuracy(fcast, ts1Test)
```

# unsupervised learning
bisogna creare cluster dei dati che si sono osservati
costruire predictors per quei cluster

### iris ignoring species labels
```{r}
data(iris); library(ggplot2)
inTrain <- createDataPartition(y = iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]

```
### cluster with k-means
```{r}
## creo tre cluster diversi ignorando ovviamente la specie
kMeans1 <- kmeans(subset(training,select = -c(Species)), centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width, Petal.Length, colour = clusters, data = training)
```
### compare to real labels
```{r}
table(kMeans1$cluster, training$Species)
```
 
### Build a predictor
```{r}
modFit <- train(clusters ~. , data = subset(training,select=-c(Species)),
                method="rpart")
table(predict(modFit,training),training$Species)
```
### Apply on test 
```{r}
testClusterPred <- predict(modFit, testing)
table(testClusterPred, testing$Species)
```

